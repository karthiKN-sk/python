{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTmbZZnKxhjQ"
      },
      "source": [
        "# Cloning the Fine Tuned Model From my GitHub\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0--KYU2xxdsA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db362ffa-a49a-41be-dbc9-80cdefd143f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'grootan_ai_task' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/karthiKN-sk/grootan_ai_task.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdujpcM3xtm9"
      },
      "source": [
        "# Download the Library/Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YhF1tps9wXBU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3e4a730-375f-41a5-9113-408572e402e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.149)\n",
            "Requirement already satisfied: supervision in /usr/local/lib/python3.11/dist-packages (0.25.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: rich.progress in /usr/local/lib/python3.11/dist-packages (0.4.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.3)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.31.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.32.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.14)\n",
            "Requirement already satisfied: contourpy>=1.0.7 in /usr/local/lib/python3.11/dist-packages (from supervision) (1.3.2)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from supervision) (0.7.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: rich>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from rich.progress) (13.9.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.10.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.5)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.12)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (1.1.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.0.0->rich.progress) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.0.0->rich.progress) (2.19.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.0.0->rich.progress) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python ultralytics supervision numpy matplotlib rich.progress transformers gradio pillow huggingface_hub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwBPpqTxQ9HG"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6nfkW4B2RBa6"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "import supervision as sv\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from rich.progress import Progress\n",
        "from typing import Dict, Tuple, Iterable, List, Optional, Set, Any\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "import os\n",
        "from huggingface_hub import login\n",
        "from datetime import timedelta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdipK6N5IKIA"
      },
      "source": [
        "# Setting HF Token in Environment variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oH4YRyCdIGvS"
      },
      "outputs": [],
      "source": [
        "token = None\n",
        "token_file = \"/content/grootan_ai_task/variables.py\"\n",
        "\n",
        "with open(token_file, \"r\") as f:\n",
        "    for line in f:\n",
        "        if line.startswith(\"HF_TOKEN=\"):\n",
        "            token = line.strip().split(\"=\", 1)[1].strip('\"').strip(\"'\")\n",
        "            break\n",
        "\n",
        "if token:\n",
        "    os.environ[\"HF_TOKEN\"] = token\n",
        "    login(token=token)\n",
        "else:\n",
        "    raise ValueError(\"HF_TOKEN not found in variables.py\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95wvjpMzQqAk"
      },
      "source": [
        "# Configuration for Zone Definitions, Color Palette, and Vehicle Turn Classification.\n",
        "\n",
        "This code snippet sets up essential constants and configurations for a vehicle tracking and turn analysis system, including color settings, polygonal zone definitions, naming schemes, turn mapping logic, and a utility function for turn-based color annotation.\n",
        "\n",
        "1. Color Palette Definition\n",
        "    * Defines a reusable color palette used for drawing zones, bounding boxes, and labels.\n",
        "    * To show time in hours:minutes:seconds format instead of just seconds\n",
        "    \n",
        "This setup provides a foundational configuration layer for visual annotation, spatial zone management, and logical turn analysis in a computer vision-based traffic monitoring system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZkVRIaZiQmA-"
      },
      "outputs": [],
      "source": [
        "COLORS = sv.ColorPalette.from_hex([\"#E6194B\", \"#3CB44B\", \"#FFE119\", \"#3C76D1\"])\n",
        "\n",
        "def format_time(seconds):\n",
        "    return str(timedelta(seconds=round(seconds)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkO7vlUM-63E"
      },
      "source": [
        "# Global Detection State Initialization for Vehicle Turn Tracking.\n",
        "\n",
        "This snippet initializes a global dictionary named detections_state that is used to persist and manage tracking data across video frames in a vehicle monitoring pipeline.\n",
        "\n",
        "Dictionary Keys:\n",
        "\n",
        "* \"**tracker_id_to_zone_id**\":\n",
        "   Maps each unique vehicle (tracker_id) to the zone ID it first appeared in.\n",
        "   Used to group and identify vehicles during processing.\n",
        "\n",
        "* \"**vehicle_paths**\":\n",
        "Tracks both the entry (in) and exit (out) zones for each vehicle.\n",
        "Format: **{tracker_id: {\"in\": zone_name, \"out\": zone_name}}**.\n",
        "\n",
        "* \"**vehicle_turns**\":\n",
        "Stores the classified type of turn for each vehicle, such as \"left_turn\", \"right_turn\", \"u_turn\", or \"straight\".\n",
        "\n",
        "This stateful object is referenced and updated throughout the processing pipeline to enable accurate vehicle path tracking and turn classification across video frames."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-tWD_02a-7cS"
      },
      "outputs": [],
      "source": [
        "detections_state = {\n",
        "    \"tracker_id_to_zone_id\": {},\n",
        "    \"vehicle_paths\": {},\n",
        "    \"vehicle_turns\": {},\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7if-apVfOx0H"
      },
      "source": [
        "# Vehicle Entry-Exit Tracking and Turn Classification Logic\n",
        "\n",
        "This function, update_detections_state, manages and updates the internal state used to track vehicle movement through predefined zones, and classifies the type of turn each vehicle makes (left, right, U-turn, or straight).\n",
        "\n",
        "Key Responsibilities:\n",
        "\n",
        "1. Track Entry Zones:\n",
        "\n",
        "    * Maps each vehicle (via its tracker ID) to the in zone where it first appeared.\n",
        "\n",
        "    * Ensures the entry point is recorded only once per vehicle.\n",
        "\n",
        "    * Detects and records the out zone where the vehicle exits.\n",
        "\n",
        "2. Turn Detection:\n",
        "\n",
        "    * Uses predefined TURN_MAPPING to determine the turn type based on zone pairs (in → out).\n",
        "\n",
        "    * Updates the vehicle_turns dictionary only when both zones are known.\n",
        "\n",
        "3. Class ID Assignment:\n",
        "\n",
        "    * Associates each detection with a zone ID for visual annotation by mapping tracker_id to its zone_id.\n",
        "\n",
        "4. Filtering Valid Detections:\n",
        "\n",
        "    * Returns only detections that have been successfully associated with zones (i.e., not class ID -1).\n",
        "\n",
        "This function plays a central role in transforming low-level detection data into high-level vehicle movement understanding, essential for turn analysis in traffic videos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IULBAHSO5Cc"
      },
      "outputs": [],
      "source": [
        "def update_detections_state(\n",
        "    detections_all: sv.Detections,\n",
        "    detections_in_zones: List[sv.Detections],\n",
        "    detections_out_zones: List[sv.Detections],\n",
        "    config: Dict[str, Any],\n",
        "    frame_idx: int,\n",
        "    state: Dict[str, Any] = detections_state\n",
        ") -> sv.Detections:\n",
        "    tracker_id_to_zone_id = state[\"tracker_id_to_zone_id\"]\n",
        "    tracker_id_to_exit_zone_id = state.setdefault(\"tracker_id_to_exit_zone_id\", {})\n",
        "    vehicle_paths = state[\"vehicle_paths\"]\n",
        "    vehicle_turns = state.setdefault(\"vehicle_turns\", {})\n",
        "    fps = config[\"video_info\"].fps\n",
        "\n",
        "    # --- Assign entry zones and track vehicle IN zone names ---\n",
        "    zone_in_names = list(config[\"zones_in\"].keys())\n",
        "    for zone_in_id, detections_in_zone in enumerate(detections_in_zones):\n",
        "        zone_name = zone_in_names[zone_in_id]\n",
        "        for tracker_id in detections_in_zone.tracker_id:\n",
        "            tracker_id_to_zone_id.setdefault(tracker_id, zone_in_id)\n",
        "\n",
        "            # Initialize vehicle path if not already present\n",
        "            vehicle_paths.setdefault(tracker_id, {\"in\": None, \"out\": None,\"in_time\": None,\"out_time\": None})\n",
        "            if vehicle_paths[tracker_id][\"in\"] is None:\n",
        "                vehicle_paths[tracker_id][\"in\"] = zone_name\n",
        "                if frame_idx is not None:\n",
        "                   vehicle_paths[tracker_id][\"in_time\"] = frame_idx / fps\n",
        "\n",
        "    # --- Count exits grouped by entry zone and track vehicle OUT zone names ---\n",
        "    zone_out_names = list(config[\"zones_out\"].keys())\n",
        "    for zone_out_id, detections_out_zone in enumerate(detections_out_zones):\n",
        "        zone_name = zone_out_names[zone_out_id]\n",
        "        for tracker_id in detections_out_zone.tracker_id:\n",
        "            if tracker_id in tracker_id_to_zone_id:\n",
        "                if vehicle_paths[tracker_id][\"out\"] is None:\n",
        "                    vehicle_paths[tracker_id][\"out\"] = zone_name\n",
        "\n",
        "                    if frame_idx is not None:\n",
        "                        timestamp_sec = frame_idx / fps\n",
        "                        vehicle_paths[tracker_id][\"out_time\"] = timestamp_sec\n",
        "                tracker_id_to_exit_zone_id[tracker_id] = zone_out_id\n",
        "\n",
        "    # --- Detect turns ---\n",
        "    for tracker_id, path in vehicle_paths.items():\n",
        "        in_zone = path[\"in\"]\n",
        "        out_zone = path[\"out\"]\n",
        "        in_time = path[\"in_time\"]\n",
        "        out_time = path[\"out_time\"]\n",
        "        if in_zone and out_zone and tracker_id not in vehicle_turns:\n",
        "            turn_type = config[\"turn_mapping\"].get((in_zone, out_zone))\n",
        "            if turn_type:\n",
        "                vehicle_turns[tracker_id] = {\n",
        "                    \"turn_type\": turn_type,\n",
        "                    \"from_zone\": in_zone,\n",
        "                    \"to_zone\": out_zone,\n",
        "                    \"in_time\": in_time,\n",
        "                    \"out_time\": out_time\n",
        "                }\n",
        "                print(f\"[TURN] Vehicle {tracker_id}: {in_zone} → {out_zone} → {turn_type},Time: {format_time(in_time)} → {format_time(out_time)}\")\n",
        "\n",
        "    # Assign class_id based on EXIT zone\n",
        "    if len(detections_all) > 0:\n",
        "        detections_all.class_id = np.vectorize(\n",
        "            lambda x: tracker_id_to_exit_zone_id.get(x, tracker_id_to_zone_id.get(x, -1))\n",
        "        )(detections_all.tracker_id)\n",
        "    else:\n",
        "        detections_all.class_id = np.array([], dtype=int)\n",
        "\n",
        "    return detections_all[detections_all.class_id != -1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEUvpM3lQydq"
      },
      "source": [
        "# Zone Initialization and PolygonZone dictionary Utilities.\n",
        "\n",
        "This code provides two utility functions used in the vehicle turn detection system:\n",
        "1. **initiate_polygon_zones**:\n",
        "\n",
        "    * Takes a list of zone names and corresponding polygon coordinates.\n",
        "    * Initializes and returns a dictionary mapping each name to a PolygonZone object.\n",
        "\n",
        "\n",
        "These functions are key to defining spatial zones for detecting vehicle movement and labeling them appropriately in the video annotation process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6ViGjiZQy6w"
      },
      "outputs": [],
      "source": [
        "def initiate_polygon_zones(\n",
        "    names: List[str],\n",
        "    polygons: List[np.ndarray],\n",
        "    triggering_anchors: Iterable[sv.Position] = [sv.Position.CENTER],\n",
        ") -> Dict[str, sv.PolygonZone]:\n",
        "    return {\n",
        "        name: sv.PolygonZone(polygon=polygon, triggering_anchors=triggering_anchors)\n",
        "        for name, polygon in zip(names, polygons)\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OS4KoQo1PlXc"
      },
      "source": [
        "# Setup Configuration for Vehicle Turn Detection Pipeline.\n",
        "\n",
        "The **setup_video_processor** function initializes and returns a configuration dictionary containing all essential components and parameters needed to process a video for vehicle turn detection. Here's what it sets up:\n",
        "\n",
        "1. Video Input/Output Paths:\n",
        "\n",
        "      * **source_video_path**: Path to the input video.\n",
        "\n",
        "      * **target_video_path**: Optional path to save the processed output.\n",
        "\n",
        "2. Detection Parameters:\n",
        "\n",
        "      * **confidence_threshold**: Minimum confidence level for YOLO model detections.\n",
        "\n",
        "      * **iou_threshold**: IOU threshold used during object tracking.\n",
        "\n",
        "3. Detection and Tracking Tools:\n",
        "\n",
        "      * **model**: A fine-tuned YOLO model for vehicle detection.\n",
        "\n",
        "      * **tracker**: ByteTrack tracker for maintaining vehicle identities.\n",
        "\n",
        "4. Video Metadata:\n",
        "\n",
        "      * **video_info**: Extracts frame rate, resolution, and frame count from the input video.\n",
        "\n",
        "5. Zone Definitions:\n",
        "\n",
        "      * **zones**: Get polygon areas from User to detect Zones for turn classification.\n",
        "\n",
        "6. Annotation Tools:\n",
        "\n",
        "      * **box_annotator**: Draws bounding boxes on detected vehicles.\n",
        "\n",
        "      * **label_annotator**: Displays vehicle IDs.\n",
        "\n",
        "      * **trace_annotator**: Adds trajectory traces to show vehicle movement paths.\n",
        "\n",
        "7. Detection State Handler:\n",
        "\n",
        "      * **detections_manager**: A function to manage turn state updates.\n",
        "\n",
        "8. Zone Definitions (Get From User Polygons )\n",
        "\n",
        "    * ZONE_POLYGONS: List of polygonal coordinates marking entry zones for vehicles.\n",
        "    * Each polygon is an array of 2D points (x, y).\n",
        "    * Generate Zone Names Using Polygon\n",
        "\n",
        "This setup function centralizes the configuration, making it easy to pass all necessary components to the video processing pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8n6qfJvMPqPB"
      },
      "outputs": [],
      "source": [
        "def setup_video_processor(\n",
        "    source_video_path: str,\n",
        "    target_video_path: Optional[str] = None,\n",
        "    zones: Dict[str, list] = {},\n",
        "    turn_mapping: Optional[Dict[Tuple[str, str], str]] = None,\n",
        "    confidence_threshold: float = 0.4,\n",
        "    iou_threshold: float = 0.7,\n",
        ") -> Dict[str, Any]:\n",
        "\n",
        "    if not zones or not zones.get(\"entry\") or not zones.get(\"exit\"):\n",
        "        raise ValueError(\"'zones' must contain both non-empty 'entry' and 'exit' lists.\")\n",
        "\n",
        "    # Convert polygon lists to NumPy arrays\n",
        "    ZONE_IN_POLYGONS = [np.array(zone[\"points\"], dtype=np.int32) for zone in zones[\"entry\"]]\n",
        "    ZONE_OUT_POLYGONS = [np.array(zone[\"points\"], dtype=np.int32) for zone in zones[\"exit\"]]\n",
        "\n",
        "    ZONE_IN_NAMES = [zone['id'] for zone in zones[\"entry\"]]\n",
        "    ZONE_OUT_NAMES = [zone['id'] for zone in zones[\"exit\"]]\n",
        "\n",
        "    TURN_MAPPING = turn_mapping\n",
        "\n",
        "    return {\n",
        "        \"conf_threshold\": confidence_threshold,\n",
        "        \"iou_threshold\": iou_threshold,\n",
        "        \"source_video_path\": source_video_path,\n",
        "        \"target_video_path\": target_video_path,\n",
        "        \"model\": YOLO(\"/content/grootan_ai_task/models/YoloFineTunedV3.pt\"),\n",
        "        \"tracker\": sv.ByteTrack(),\n",
        "        \"video_info\": sv.VideoInfo.from_video_path(source_video_path),\n",
        "        \"zones_in\": initiate_polygon_zones(ZONE_IN_NAMES,ZONE_IN_POLYGONS),\n",
        "        \"zones_out\": initiate_polygon_zones(ZONE_OUT_NAMES,ZONE_OUT_POLYGONS),\n",
        "        \"box_annotator\": sv.BoxAnnotator(color=COLORS),\n",
        "        \"label_annotator\": sv.LabelAnnotator(color=COLORS, text_color=sv.Color.BLACK),\n",
        "        \"trace_annotator\": sv.TraceAnnotator(\n",
        "            color=COLORS, position=sv.Position.CENTER, trace_length=100, thickness=2\n",
        "        ),\n",
        "        \"detections_manager\": update_detections_state,\n",
        "        \"turn_mapping\": TURN_MAPPING\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HffnMCTqKCu"
      },
      "source": [
        "# Analyze and Visualize Vehicle Turn Statistics\n",
        "\n",
        "The **analyze_turns** function evaluates vehicle turn data to generate a summary of turn behavior and visual insights. Here's what it does:\n",
        "\n",
        "1. Summary Computation:\n",
        "    *  Counts total tracked vehicles.\n",
        "    *  Computes how many made right turns, left turns, U-turns, or went straight.\n",
        "\n",
        "2. Console Output:\n",
        "    *   Prints a summary report of the turn counts to the terminal.\n",
        "\n",
        "3. Data Packaging:\n",
        "    *   Creates a JSON-style dictionary (**turn_message**) containing:\n",
        "        *   A message,\n",
        "        *   Overall turn statistics (**turn_counts**),\n",
        "        *   Individual vehicle turn details by tracker ID (**turn_details**).\n",
        "\n",
        "\n",
        "4. Visualization:\n",
        "\n",
        "      *   Plots a bar chart using **matplotlib** to visually represent the count of each turn type.\n",
        "      *   Saves the chart as **turn_analysis.png** for later use (e.g., appending to video).\n",
        "\n",
        "5. Return:\n",
        "      *   Outputs the structured **turn_message**, suitable for downstream use in reports or QA systems.\n",
        "\n",
        "This function bridges raw detection data with user-friendly output, supporting both analysis and visualization of vehicle behavior.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2x9VkqF5qKm2"
      },
      "outputs": [],
      "source": [
        "def analyze_turns(vehicle_turns):\n",
        "    \"\"\"Analyze the turns and create summary statistics\"\"\"\n",
        "    total_vehicles = len(vehicle_turns)\n",
        "    if total_vehicles == 0:\n",
        "        raise ValueError(\"No vehicles were detected or tracked.\")\n",
        "    # Count the different types of turns\n",
        "    right_turns = sum(1 for turns in vehicle_turns.values() if turns[\"turn_type\"] == \"right_turn\" )\n",
        "    left_turns = sum(1 for turns in vehicle_turns.values() if turns[\"turn_type\"] == \"left_turn\" )\n",
        "    u_turns = sum(1 for turns in vehicle_turns.values() if turns[\"turn_type\"] == \"u_turn\" )\n",
        "    no_turns = sum(1 for turns in vehicle_turns.values() if turns[\"turn_type\"] == \"straight\")\n",
        "\n",
        "    print(\"\\n--- Turn Analysis Results ---\")\n",
        "    print(f\"Total unique vehicles tracked: {total_vehicles}\")\n",
        "    print(f\"Vehicles making right turns: {right_turns} \")\n",
        "    print(f\"Vehicles making left turns: {left_turns}\")\n",
        "    print(f\"Vehicles making U-turns: {u_turns}\")\n",
        "    print(f\"Vehicles with no detected turns: {no_turns}\")\n",
        "\n",
        "\n",
        "    # Create a visualization\n",
        "    turn_counts = {\n",
        "        'Right Turn': right_turns,\n",
        "        'Left Turn': left_turns,\n",
        "        'U-Turn': u_turns,\n",
        "        'No Turn': no_turns\n",
        "    }\n",
        "\n",
        "    turn_message = {\n",
        "    \"message\": \"Turn Analysis Results completed.\",\n",
        "    \"total_vehicles\": total_vehicles,\n",
        "    \"turn_counts\": {\n",
        "        \"Vehicles making right turns\" : right_turns,\n",
        "        \"Vehicles making left turns\": left_turns,\n",
        "        \"Vehicles making U-turns\": u_turns,\n",
        "        \"Vehicles with no detected turns (Straight)\": no_turns\n",
        "    },\n",
        "    \"turn_details\": [\n",
        "            {\n",
        "                \"tracker_id\": int(tracker_id),\n",
        "                \"turn\": data[\"turn_type\"],\n",
        "                \"from\": data[\"from_zone\"],\n",
        "                \"to\": data[\"to_zone\"],\n",
        "                \"in_time\": data['in_time'],\n",
        "                \"out_time\": data['out_time']\n",
        "            }\n",
        "            for tracker_id, data in vehicle_turns.items()\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    colors = ['red', 'green', 'black', 'blue']\n",
        "    plt.bar(turn_counts.keys(), turn_counts.values(), color=colors)\n",
        "    plt.title('Vehicle Turn Analysis')\n",
        "    plt.ylabel('Number of Vehicles')\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "    # Add count labels on top of each bar\n",
        "    for i, (key, value) in enumerate(turn_counts.items()):\n",
        "        plt.text(i, value + 0.3, str(value), ha='center')\n",
        "\n",
        "    plt.savefig('turn_analysis.png')\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "    return turn_message"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNh4F1DGRnav"
      },
      "source": [
        "# Annotate Video Frames with Zone Information and Vehicle Turn Statistics\n",
        "\n",
        "\n",
        "The **annotate_frame** function overlays comprehensive visual annotations on each video frame to aid in understanding vehicle movement and behavior. Here's what it does:\n",
        "\n",
        "1. Draws zones on the frame using polygons and labels with distinct colors.\n",
        "\n",
        "2. Generates labels for each detected vehicle using their tracker IDs (e.g., **\"Car #12\"**).\n",
        "\n",
        "3. Applies multiple annotation layers:\n",
        "    *   Trajectory traces via **trace_annotator**\n",
        "    *   Bounding boxes via **box_annotator**\n",
        "    *   Vehicle ID labels via **label_annotator**\n",
        "\n",
        "4. Computes turn statistics from the global detections_state:\n",
        "    *   Total vehicles tracked\n",
        "    *   Counts of right turns, left turns, U-turns, and straight movements\n",
        "\n",
        "5. Displays summary metrics visually on the frame, including:\n",
        "    *   A detection count badge\n",
        "    *   Fixed-position statistics on turn types, color-coded for clarity (e.g., red for right turns, green for left turns, etc.)\n",
        "\n",
        "This function is central to making the video output interpretable by overlaying both spatial (zones) and behavioral (turn types) information for each detected vehicle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Puz5Hu3mRlus"
      },
      "outputs": [],
      "source": [
        "def annotate_frame(frame: np.ndarray, detections: sv.Detections, config: Dict[str, Any]) -> np.ndarray:\n",
        "    frame_ = frame.copy()\n",
        "\n",
        "    # Draw zones\n",
        "    for i, ((zin_name, zin), (zout_name, zout)) in enumerate(zip(config[\"zones_in\"].items(), config[\"zones_out\"].items())):\n",
        "        in_color = sv.Color(b=0, g=255, r=0)\n",
        "        out_color = sv.Color(b=0, g=0, r=255)\n",
        "        zin_anchor = sv.get_polygon_center(zin.polygon)\n",
        "        zout_anchor = sv.get_polygon_center(zout.polygon)\n",
        "        frame_ = sv.draw_polygon(frame_, zin.polygon, in_color)\n",
        "        frame_ = sv.draw_text(frame_, text=zin_name, text_anchor=zin_anchor, text_color=in_color)\n",
        "        frame_ = sv.draw_polygon(frame_, zout.polygon, out_color)\n",
        "        frame_ = sv.draw_text(frame_, text=zout_name, text_anchor=zout_anchor, text_color=out_color)\n",
        "\n",
        "    vehicle_turns= detections_state[\"vehicle_turns\"]\n",
        "\n",
        "    labels = [f\"Car #{id_}\" for id_ in detections.tracker_id]\n",
        "    frame_ = config[\"trace_annotator\"].annotate(frame_, detections)\n",
        "    frame_ = config[\"box_annotator\"].annotate(frame_, detections)\n",
        "    frame_ = config[\"label_annotator\"].annotate(frame_, detections, labels)\n",
        "\n",
        "    # Count the different types of turns\n",
        "    total_vehicles = len(vehicle_turns)\n",
        "    right_turns = sum(1 for turns in vehicle_turns.values() if turns[\"turn_type\"] == \"right_turn\" )\n",
        "    left_turns = sum(1 for turns in vehicle_turns.values() if turns[\"turn_type\"] == \"left_turn\" )\n",
        "    u_turns = sum(1 for turns in vehicle_turns.values() if turns[\"turn_type\"] == \"u_turn\" )\n",
        "    no_turns = sum(1 for turns in vehicle_turns.values() if turns[\"turn_type\"] == \"straight\")\n",
        "\n",
        "    # Add detection count info\n",
        "    total_count = len(detections)\n",
        "    frame_ = sv.draw_text(\n",
        "        frame_,\n",
        "        f\"Detected: {total_count}\",\n",
        "        sv.Point(50, 50),\n",
        "        background_color=sv.Color.from_hex(\"#FF7F50\")\n",
        "    )\n",
        "    # Draw fixed turn statistics on the center-left of the frame\n",
        "    start_x = 80\n",
        "    start_y = 350\n",
        "    line_spacing = 40\n",
        "    text_color = sv.Color(r=255, g=255, b=255)\n",
        "\n",
        "    # Line 1: Total vehicles tracked\n",
        "    frame_ = sv.draw_text(\n",
        "        frame_,\n",
        "        text=f\"Total vehicles tracked: {total_vehicles}\",\n",
        "        text_anchor=sv.Point(start_x + 30, start_y),\n",
        "        background_color=sv.Color.from_hex(\"#DDDDDD\"),\n",
        "    )\n",
        "\n",
        "    # Line 2: Right turns (Red)\n",
        "    frame_ = sv.draw_text(\n",
        "        frame_,\n",
        "        text=f\"Right turns: {right_turns}\",\n",
        "        text_anchor=sv.Point(start_x + 10, start_y + line_spacing),\n",
        "        background_color=sv.Color(r=255, g=0, b=0),\n",
        "        text_color=text_color\n",
        "    )\n",
        "\n",
        "    # Line 3: Left turns (Green)\n",
        "    frame_ = sv.draw_text(\n",
        "        frame_,\n",
        "        text=f\"Left turns: {left_turns}\",\n",
        "        text_anchor=sv.Point(start_x + 10, start_y + 2 * line_spacing),\n",
        "        background_color=sv.Color(r=0, g=255, b=0),\n",
        "\n",
        "    )\n",
        "\n",
        "    # Line 4: U-turns (Black)\n",
        "    frame_ = sv.draw_text(\n",
        "        frame_,\n",
        "        text=f\"U-turns: {u_turns}\",\n",
        "        text_anchor=sv.Point(start_x + 10, start_y + 3 * line_spacing),\n",
        "        background_color=sv.Color(r=0, g=0, b=0),\n",
        "        text_color=text_color\n",
        "    )\n",
        "\n",
        "    # Line 5: No turns (Blue)\n",
        "    frame_ = sv.draw_text(\n",
        "        frame_,\n",
        "        text=f\"No turns: {no_turns}\",\n",
        "        text_anchor=sv.Point(start_x + 10, start_y + 4 * line_spacing),\n",
        "        background_color=sv.Color(r=0, g=0, b=255),\n",
        "        text_color=text_color\n",
        "    )\n",
        "\n",
        "\n",
        "    return frame_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFjmcj3g-wSx"
      },
      "source": [
        "# Process and Annotate Video Frame for Vehicle Turn Detection\n",
        "\n",
        "The function **process_frame** handles a single video frame in the vehicle turn detection pipeline. Here's a breakdown of its functionality:\n",
        "\n",
        "1. Runs object detection on the input frame using a **YOLO model (from config[\"model\"])**, with specified confidence and IoU thresholds.\n",
        "\n",
        "2. Converts detection results into a standardized format (**sv.Detections**) and forces all detected class IDs to zero (indicating a single-class tracking scenario, like vehicles).\n",
        "\n",
        "3. Updates object tracks using a tracking algorithm (**config[\"tracker\"]**).\n",
        "\n",
        "4. Checks zone: it filters detections currently inside these zones.\n",
        "\n",
        "5. Filters detections further using a custom **detections_manager** function that processes zone-based transitions to determine vehicle turns.\n",
        "\n",
        "6. Annotates the frame (e.g., drawing bounding boxes and turn labels) using the **annotate_frame** function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-RAl0Wo5-vF2"
      },
      "outputs": [],
      "source": [
        "def process_frame(frame: np.ndarray, frame_idx: int, config: Dict[str, Any]) -> np.ndarray:\n",
        "    result = config[\"model\"](frame, verbose=False, conf=config[\"conf_threshold\"], iou=config[\"iou_threshold\"])[0]\n",
        "    detections = sv.Detections.from_ultralytics(result)\n",
        "    detections.class_id = np.zeros(len(detections))\n",
        "    detections = config[\"tracker\"].update_with_detections(detections)\n",
        "\n",
        "    detections_in_zones, detections_out_zones = [], []\n",
        "    for zone_in, zone_out in zip(config[\"zones_in\"].values(), config[\"zones_out\"].values()):\n",
        "        in_zone = detections[zone_in.trigger(detections)]\n",
        "        out_zone = detections[zone_out.trigger(detections)]\n",
        "        detections_in_zones.append(in_zone)\n",
        "        detections_out_zones.append(out_zone)\n",
        "\n",
        "    filtered = config[\"detections_manager\"](detections, detections_in_zones, detections_out_zones, config, frame_idx)\n",
        "    return annotate_frame(frame, filtered, config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KN-dsim3RcgV"
      },
      "source": [
        "# Process and Annotate Video Frames for Vehicle Turn Detection\n",
        "\n",
        "The **process_video** function reads a video frame-by-frame, processes each frame to detect and annotate vehicles, and outputs the results either to a video file or a live display window. Here's what it does:\n",
        "\n",
        "1. Frame Extraction: Uses a frame generator to read frames from the source video.\n",
        "\n",
        "2. Progress Tracking: Displays a live progress bar using the rich library to monitor video processing.\n",
        "\n",
        "3. Annotation Pipeline:\n",
        "    *   For each frame, it calls **process_frame**() to detect vehicles, determine turn behavior, and apply annotations.\n",
        "\n",
        "4. Output Handling:\n",
        "\n",
        "    *   If output path is specified: Saves the annotated video to disk using VideoSink.\n",
        "    *   Otherwise: Displays annotated frames live using OpenCV (**cv2.imshow**).\n",
        "\n",
        "5. Sample Frame Export: Saves a single annotated frame as an image (annotated_output.png) for preview or debugging.\n",
        "\n",
        "6. Returns the dictionary of vehicle turn states (vehicle_turns) tracked during the video processing.\n",
        "\n",
        "This function is the core executor of the turn detection pipeline, enabling both real-time display and file output of the analyzed results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "za412PJPRcA4"
      },
      "outputs": [],
      "source": [
        "def process_video(config: Dict[str, Any]) -> None:\n",
        "    frame_generator = sv.get_video_frames_generator(config[\"source_video_path\"])\n",
        "    total = config[\"video_info\"].total_frames\n",
        "\n",
        "    with Progress() as progress:\n",
        "        task = progress.add_task(\"[green]Processing video...\", total=total)\n",
        "        if config[\"target_video_path\"]:\n",
        "            with sv.VideoSink(config[\"target_video_path\"], config[\"video_info\"]) as sink:\n",
        "                saved_sample = False\n",
        "                for frame_idx, frame in enumerate(frame_generator):\n",
        "                    annotated = process_frame(frame, frame_idx, config)\n",
        "                    sink.write_frame(annotated)\n",
        "                    if not saved_sample:\n",
        "                        cv2.imwrite(\"annotated_output.png\", annotated)\n",
        "                        saved_sample = True\n",
        "                    progress.advance(task)\n",
        "        else:\n",
        "            for frame in frame_generator:\n",
        "                annotated = process_frame(frame, config)\n",
        "                cv2.imshow(\"Processed Video\", annotated)\n",
        "                if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "                    break\n",
        "                progress.advance(task)\n",
        "            cv2.destroyAllWindows()\n",
        "\n",
        "    return detections_state[\"vehicle_turns\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NG4ESNuq9Zs"
      },
      "source": [
        "# Append Turn Analysis Summary Chart to Video Output\n",
        "\n",
        "The function add_final_summary_to_video enhances a processed video by appending a visual summary of vehicle turn statistics at the end. Here's what it does:\n",
        "\n",
        "1. Analyzes turn data using the provided vehicle turn state.\n",
        "\n",
        "2. Loads a bar chart image (turn_analysis.png) that visually represents turn statistics.\n",
        "\n",
        "3. Reads and copies all frames from the original processed video.\n",
        "\n",
        "4. Appends the chart image as static frames for 5 seconds at the end of the video.\n",
        "\n",
        "5. Saves the new video with the summary chart to the specified output path.\n",
        "\n",
        "6. Returns a structured JSON summary of the vehicle turn data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rm56mopSq6ts"
      },
      "outputs": [],
      "source": [
        "def add_final_summary_to_video(video_path, vehicle_turns, output_path=\"final_output.mp4\"):\n",
        "    \"\"\"Add a final summary frame to the end of the video\"\"\"\n",
        "\n",
        "    # First analyze the turns\n",
        "    vehicle_turn_json = analyze_turns(vehicle_turns)\n",
        "\n",
        "    # Load the bar chart image\n",
        "    chart_img = cv2.imread(\"turn_analysis.png\")\n",
        "    if chart_img is None:\n",
        "        raise FileNotFoundError(\"turn_analysis.png not found.\")\n",
        "\n",
        "    # Read the original video\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "    # Resize chart to match video resolution\n",
        "    chart_img = cv2.resize(chart_img, (width, height))\n",
        "\n",
        "    # Create the output video\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v') #mp4v h264\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    # Copy all frames from the original video\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        out.write(frame)\n",
        "\n",
        "    # Append chart image as 5 seconds of frames\n",
        "    for _ in range(int(fps * 5)):\n",
        "        out.write(chart_img)\n",
        "\n",
        "    # Release resources\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    print(f\"Final video with chart saved as '{output_path}'\")\n",
        "\n",
        "    return vehicle_turn_json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdmIGrtbq5eV"
      },
      "source": [
        "# Init Video Processing (Full Video-Based Vehicle Turn Detection and Summary Pipeline)\n",
        "\n",
        "This function **run_full_vehicle_turn_pipeline** performs the complete pipeline for analyzing vehicle movements in a video. It:\n",
        "\n",
        "1. Processes the input video using a configured video processor to detect and trace vehicle movements.\n",
        "\n",
        "2. Analyzes vehicle turns (left, right, U-turn, straight) and records them.\n",
        "\n",
        "3. Generates a summary chart of the turn statistics and appends it to the output video.\n",
        "\n",
        "4. Returns a JSON summary of vehicle turn analytics for further use (e.g., visualization or question answering).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ek-5O71YrFnp"
      },
      "outputs": [],
      "source": [
        "def run_full_vehicle_turn_pipeline(\n",
        "    source_video_path: str,\n",
        "    final_output_path: str = \"final_output.mp4\",\n",
        "    zones: Dict[str, list] = {},\n",
        "    turn_mappings: List[Dict[str, str]] = []\n",
        "):\n",
        "    \"\"\"\n",
        "    Runs the full pipeline: processes video, tracks turns, and appends summary.\n",
        "    \"\"\"\n",
        "    if not zones or not zones.get(\"entry\") or not zones.get(\"exit\"):\n",
        "        raise ValueError(\"'zones' must contain both non-empty 'entry' and 'exit' lists.\")\n",
        "\n",
        "    # Build the mapping dict\n",
        "    def build_turn_mapping_dict(mapping_list):\n",
        "        TURN_TYPE_MAPPING = {\n",
        "            \"left\": \"left_turn\",\n",
        "            \"right\": \"right_turn\",\n",
        "            \"straight\": \"straight\",\n",
        "            \"u-turn\": \"u_turn\"\n",
        "        }\n",
        "\n",
        "        return {\n",
        "            (m[\"from_zone\"], m[\"to_zone\"]): TURN_TYPE_MAPPING.get(m[\"turn_type\"], m[\"turn_type\"])\n",
        "            for m in mapping_list\n",
        "        }\n",
        "\n",
        "    mapping_dict = build_turn_mapping_dict(turn_mappings)\n",
        "\n",
        "    # Step 1: Setup and process the video\n",
        "    config = setup_video_processor(\n",
        "        source_video_path=source_video_path,\n",
        "        target_video_path=\"output_traced.mp4\",\n",
        "        zones=zones,\n",
        "        turn_mapping=mapping_dict\n",
        "    )\n",
        "    vehicle_turns_state = process_video(config)\n",
        "\n",
        "    # Step 2: Append summary chart to the traced video\n",
        "    vehicle_turn_json = add_final_summary_to_video(\n",
        "        video_path=\"output_traced.mp4\",\n",
        "        vehicle_turns=vehicle_turns_state,\n",
        "        output_path=final_output_path\n",
        "    )\n",
        "\n",
        "    return vehicle_turn_json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewXOvNlM-_26"
      },
      "source": [
        "# Vehicle Turn Detection Summary & AI-Powered Question Answering.\n",
        "**convert_turn_stats_to_text(analysis_result)**:\n",
        "Converts the vehicle turn detection results (a JSON dictionary) into a readable text summary, including:\n",
        "\n",
        "1. Total vehicle count\n",
        "\n",
        "2. Turn type counts (right, left, U-turn, straight)\n",
        "\n",
        "3. Per-vehicle turn information.\n",
        "\n",
        "**Use:**\n",
        "This summary is later passed to a language model for answering questions.\n",
        "\n",
        "**create_pipeline(text_data)**:\n",
        "Creates a custom question-answering function qa_pipeline(question) that:\n",
        "\n",
        "1. Takes a natural language question\n",
        "\n",
        "2. Feeds it to Qwen along with the vehicle turn summary\n",
        "\n",
        "3. Returns only the assistant's reply from the model output\n",
        "\n",
        "**Purpose:**\n",
        "This abstracts the model usage so the user can ask follow-up questions based on video analytics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "es4286u__GMU"
      },
      "outputs": [],
      "source": [
        "def convert_turn_stats_to_text(analysis_result):\n",
        "    turn_counts = analysis_result.get(\"turn_counts\", {})\n",
        "    turn_details = analysis_result.get(\"turn_details\", [])\n",
        "\n",
        "    total = analysis_result.get(\"total_vehicles\", 0)\n",
        "    right = turn_counts.get(\"Vehicles making right turns\", 0)\n",
        "    left = turn_counts.get(\"Vehicles making left turns\", 0)\n",
        "    u_turn = turn_counts.get(\"Vehicles making U-turns\", 0)\n",
        "    straight = turn_counts.get(\"Vehicles with no detected turns (Straight)\", 0)\n",
        "\n",
        "    summary_text = (\n",
        "    f\"A total of {total} cars were tracked during the analysis. \"\n",
        "    f\"Among them, {right} made right turns, {left} made left turns, \"\n",
        "    f\"{u_turn} performed U-turns (also referred to as 'uturns' or 'reverse turns'), and {straight} continued straight without making any turns. (also referred to as 'no turns')\"\n",
        "    )\n",
        "\n",
        "    if turn_details:\n",
        "        detail_sentences = detail_sentences = [\n",
        "            f\"Vehicle ID {item['tracker_id']} (also referred to as 'car' or 'car with tracker ID') \"\n",
        "            f\"made a {item['turn'].replace('_', ' ').lower()} from {item['from']} at (Time: {format_time(item['in_time'])}) \"\n",
        "            f\"to {item['to']} at (Time: {format_time(item['out_time'])}).\"\n",
        "            for item in turn_details\n",
        "        ]\n",
        "        details_text = \"\\n\".join(detail_sentences)\n",
        "        return f\"{summary_text}{details_text}\"\n",
        "    else:\n",
        "        return f\"{summary_text}. No individual vehicle turn details were recorded.\"\n",
        "\n",
        "\n",
        "\n",
        "# Load Qwen model and tokenizer (only once globally)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-1.5B-Instruct\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-1.5B-Instruct\")\n",
        "generation_pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "\n",
        "\n",
        "def create_pipeline(text_data):\n",
        "    \"\"\"\n",
        "    Create a simple function to handle QA using Qwen with the full text_data\n",
        "    \"\"\"\n",
        "    def qa_pipeline(question):\n",
        "        text = f\"\"\"\n",
        "        You are an expert in analyzing traffic video data, specifically vehicle turn behavior.\n",
        "\n",
        "        Answer the question as thoroughly as possible using only the provided context. If the answer is not present in the context, respond with: \"Answer is not available in the context.\" Do not provide fabricated or assumed information.\n",
        "\n",
        "        Context:\n",
        "        {text_data}\n",
        "\n",
        "        Based on the above context, answer the following question clearly and concisely:\n",
        "\n",
        "        Question:\n",
        "        {question}\n",
        "        \"\"\"\n",
        "\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"You are an expert in vehicle turn analysis. Respond clearly and accurately using only the provided context.\"},\n",
        "            {\"role\": \"user\", \"content\": text},\n",
        "        ]\n",
        "        response = generation_pipe(messages, max_new_tokens=1000)[0]\n",
        "        print(response)\n",
        "        assistant_response = \"\"\n",
        "        for msg in response['generated_text']:\n",
        "            if msg.get(\"role\") == \"assistant\":\n",
        "                assistant_response = msg.get(\"content\", \"\")\n",
        "                break\n",
        "        return assistant_response\n",
        "\n",
        "    return qa_pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyJSSXxLS5VZ"
      },
      "source": [
        "# Vehicle Turn Detection with Interactive Zone Drawing Using Gradio\n",
        "Interactive Vehicle Turn Detection with Zone-Based Video Analysis\n",
        "\n",
        "**gradio** is used to create an interactive web UI for uploading a video, processing it, and asking questions.\n",
        "\n",
        "**tempfile** is used to handle temporary storage of the uploaded video.\n",
        "\n",
        "This Python application provides an interactive web interface to detect vehicle turns in traffic videos by allowing users to manually draw polygonal zones on the first video frame. Built using Gradio for the UI and OpenCV for video processing, the tool enables the following workflow:\n",
        "\n",
        "1. Upload a traffic video in common formats like MP4.\n",
        "\n",
        "2. Extract and display the first frame of the video for zone drawing.\n",
        "\n",
        "3. Draw multiple polygonal zones In/Out(Z1, Z2, Z3, Z4, etc.) on the frame to define regions of interest in an intersection pattern.\n",
        "\n",
        "4. Visualize the drawn zones with distinct colors and labels.\n",
        "\n",
        "5. Analyze the video based on the defined zones to detect vehicle turns and movements.\n",
        "\n",
        "6. View the processed video highlighting vehicle turn events.\n",
        "\n",
        "7. Interact with the analysis by asking questions about vehicle turns through a natural language interface powered by a custom pipeline.\n",
        "\n",
        "\n",
        "(**encode_to_browser_safe_mp4**): This function converts a video file to a browser-safe MP4 format using **ffmpeg**.To transcode a video (any format) into an MP4 file that's optimized for web playback in browsers (like Chrome, Firefox, Safari, etc.).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import tempfile\n",
        "import subprocess\n",
        "import cv2\n",
        "import numpy as np\n",
        "import json\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Persistent state for document store and pipeline\n",
        "global_turn_json = None\n",
        "global_pipeline = None\n",
        "\n",
        "class ZoneDrawer:\n",
        "    def __init__(self):\n",
        "        # Simplified structure for Step 1: Only direction, no turn types yet\n",
        "        self.zones = []  # Each zone: {'id': 'Z1', 'direction': 'in', 'points': [[x,y],...]}\n",
        "        self.turn_mappings = []  # Each mapping: {'from_zone': 'Z1', 'to_zone': 'Z2', 'turn_type': 'left'}\n",
        "        self.zone_counter = 1\n",
        "        self.current_frame = None\n",
        "        self.current_direction = 'in'  # 'in' or 'out'\n",
        "        self.video_path = None\n",
        "\n",
        "    def process_video(self, video_file):\n",
        "        \"\"\"Extract first frame from uploaded video\"\"\"\n",
        "        if video_file is None:\n",
        "            return None, \"Please upload a video file first.\"\n",
        "\n",
        "        try:\n",
        "            self.video_path = video_file\n",
        "            cap = cv2.VideoCapture(video_file)\n",
        "            ret, frame = cap.read()\n",
        "            cap.release()\n",
        "\n",
        "            if not ret:\n",
        "                return None, \"❌ Could not extract frame from video.\"\n",
        "\n",
        "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            self.current_frame = frame_rgb\n",
        "\n",
        "            return frame_rgb, f\"✅ Video loaded! Frame size: {frame_rgb.shape[1]}x{frame_rgb.shape[0]}. Draw IN and OUT zones.\"\n",
        "\n",
        "        except Exception as e:\n",
        "            return None, f\"❌ Error processing video: {str(e)}\"\n",
        "\n",
        "    def set_zone_direction(self, direction):\n",
        "        \"\"\"Set current zone direction (in/out)\"\"\"\n",
        "        self.current_direction = direction\n",
        "        color = \"🟢 GREEN\" if direction == 'in' else \"🔴 RED\"\n",
        "        return f\"Drawing mode: {direction.upper()} zones ({color})\"\n",
        "\n",
        "    def process_drawing(self, image_data):\n",
        "        \"\"\"Process the drawn image and extract polygon points - Step 1: Only direction\"\"\"\n",
        "        if image_data is None:\n",
        "            return None, \"No drawing data received.\"\n",
        "\n",
        "        try:\n",
        "            # Convert the drawing to numpy array\n",
        "            if isinstance(image_data, dict) and 'layers' in image_data:\n",
        "                drawing = image_data['layers'][0] if image_data['layers'] else image_data['background']\n",
        "            else:\n",
        "                drawing = image_data\n",
        "\n",
        "            if isinstance(drawing, Image.Image):\n",
        "                drawing_array = np.array(drawing)\n",
        "            else:\n",
        "                drawing_array = drawing\n",
        "\n",
        "            points = self.extract_polygon_points(drawing_array)\n",
        "\n",
        "            if len(points) < 3:\n",
        "                return self.show_current_zones(), \"⚠️ Please draw a polygon with at least 3 points.\"\n",
        "\n",
        "            # Create new zone with only direction (no turn type yet)\n",
        "            zone_id = f\"Z{self.zone_counter}\"\n",
        "            new_zone = {\n",
        "                'id': zone_id,\n",
        "                'direction': self.current_direction,  # 'in' or 'out'\n",
        "                'points': points\n",
        "            }\n",
        "\n",
        "            self.zones.append(new_zone)\n",
        "            self.zone_counter += 1\n",
        "\n",
        "            result_image = self.create_zone_visualization()\n",
        "\n",
        "            total_zones = len(self.zones)\n",
        "            in_count = len([z for z in self.zones if z['direction'] == 'in'])\n",
        "            out_count = len([z for z in self.zones if z['direction'] == 'out'])\n",
        "\n",
        "            return result_image, f\"✅ Added {zone_id} ({self.current_direction.upper()})! Total: {total_zones} (In={in_count}, Out={out_count})\"\n",
        "\n",
        "        except Exception as e:\n",
        "            return self.show_current_zones(), f\"❌ Error processing drawing: {str(e)}\"\n",
        "\n",
        "    def extract_polygon_points(self, drawing_array):\n",
        "        \"\"\"Extract polygon points from drawn image\"\"\"\n",
        "        if len(drawing_array.shape) == 3:\n",
        "            gray = cv2.cvtColor(drawing_array, cv2.COLOR_RGB2GRAY)\n",
        "        else:\n",
        "            gray = drawing_array\n",
        "\n",
        "        contours, _ = cv2.findContours(gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        if not contours:\n",
        "            return []\n",
        "\n",
        "        largest_contour = max(contours, key=cv2.contourArea)\n",
        "        epsilon = 0.02 * cv2.arcLength(largest_contour, True)\n",
        "        approx = cv2.approxPolyDP(largest_contour, epsilon, True)\n",
        "        points = [[int(point[0][0]), int(point[0][1])] for point in approx]\n",
        "\n",
        "        return points\n",
        "\n",
        "    def create_zone_visualization(self):\n",
        "        \"\"\"Create visualization with all zones - simplified for Step 1\"\"\"\n",
        "        if self.current_frame is None:\n",
        "            return None\n",
        "\n",
        "        vis_frame = self.current_frame.copy()\n",
        "\n",
        "        # Draw all zones (simplified - no turn types shown yet)\n",
        "        for zone in self.zones:\n",
        "            direction = zone['direction']\n",
        "            zone_points = zone['points']\n",
        "            zone_id = zone['id']\n",
        "\n",
        "            if len(zone_points) >= 3:\n",
        "                pts = np.array(zone_points, np.int32)\n",
        "\n",
        "                # Color based on direction: Green for 'in', Red for 'out'\n",
        "                color = (0, 255, 0) if direction == 'in' else (255, 0, 0)  # Green or Red\n",
        "\n",
        "                # Draw filled polygon with transparency\n",
        "                overlay = vis_frame.copy()\n",
        "                cv2.fillPoly(overlay, [pts], color)\n",
        "                cv2.addWeighted(vis_frame, 0.7, overlay, 0.3, 0, vis_frame)\n",
        "\n",
        "                # Draw border\n",
        "                cv2.polylines(vis_frame, [pts], isClosed=True, color=color, thickness=3)\n",
        "\n",
        "                # Add simple zone label (no turn type yet)\n",
        "                center = np.mean(pts, axis=0).astype(int)\n",
        "                direction_abbr = \"IN\" if direction == 'in' else \"OUT\"\n",
        "                zone_text = f\"{zone_id}-{direction_abbr}\"\n",
        "\n",
        "                # Draw background and text\n",
        "                font_scale = 0.7\n",
        "                thickness = 2\n",
        "                (text_width, text_height), baseline = cv2.getTextSize(zone_text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness)\n",
        "\n",
        "                text_x = center[0] - text_width // 2\n",
        "                text_y = center[1] + text_height // 2\n",
        "\n",
        "                cv2.rectangle(vis_frame,\n",
        "                            (text_x - 5, text_y - text_height - 5),\n",
        "                            (text_x + text_width + 5, text_y + 5),\n",
        "                            (0, 0, 0), -1)\n",
        "\n",
        "                cv2.putText(vis_frame, zone_text, (text_x, text_y),\n",
        "                          cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255, 255, 255), thickness)\n",
        "\n",
        "        # Draw turn mappings as arrows (with turn type labels)\n",
        "        for mapping in self.turn_mappings:\n",
        "            from_zone = next((z for z in self.zones if z['id'] == mapping['from_zone']), None)\n",
        "            to_zone = next((z for z in self.zones if z['id'] == mapping['to_zone']), None)\n",
        "\n",
        "            if from_zone and to_zone:\n",
        "                from_center = np.mean(np.array(from_zone['points']), axis=0).astype(int)\n",
        "                to_center = np.mean(np.array(to_zone['points']), axis=0).astype(int)\n",
        "\n",
        "                # Draw arrow between zones\n",
        "                cv2.arrowedLine(vis_frame, tuple(from_center), tuple(to_center),\n",
        "                              (255, 255, 0), 4, tipLength=0.1)  # Yellow arrows\n",
        "\n",
        "                # Add turn type label on the arrow\n",
        "                arrow_center = ((from_center[0] + to_center[0]) // 2, (from_center[1] + to_center[1]) // 2)\n",
        "                turn_text = mapping['turn_type']\n",
        "\n",
        "                cv2.circle(vis_frame, arrow_center, 15, (255, 255, 0), -1)\n",
        "                cv2.putText(vis_frame, turn_text, (arrow_center[0] - 8, arrow_center[1] + 5),\n",
        "                          cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 0), 1)\n",
        "\n",
        "        return vis_frame\n",
        "\n",
        "    def show_current_zones(self):\n",
        "        \"\"\"Show current zones without adding new ones\"\"\"\n",
        "        return self.create_zone_visualization()\n",
        "\n",
        "    def create_turn_mapping(self, from_zone_id, to_zone_id, turn_type):\n",
        "        \"\"\"Create a turn mapping between two zones with specified turn type\"\"\"\n",
        "        if not from_zone_id or not to_zone_id:\n",
        "            return self.show_current_zones(), \"⚠️ Please select both FROM and TO zones.\"\n",
        "\n",
        "        if from_zone_id == to_zone_id:\n",
        "            return self.show_current_zones(), \"⚠️ FROM and TO zones must be different.\"\n",
        "\n",
        "        if not turn_type:\n",
        "            return self.show_current_zones(), \"⚠️ Please select a turn type.\"\n",
        "\n",
        "        # Check if zones exist\n",
        "        from_zone = next((z for z in self.zones if z['id'] == from_zone_id), None)\n",
        "        to_zone = next((z for z in self.zones if z['id'] == to_zone_id), None)\n",
        "\n",
        "        if not from_zone or not to_zone:\n",
        "            return self.show_current_zones(), \"⚠️ Selected zones not found.\"\n",
        "\n",
        "        # Check if mapping already exists\n",
        "        existing = next((m for m in self.turn_mappings\n",
        "                        if m['from_zone'] == from_zone_id and m['to_zone'] == to_zone_id), None)\n",
        "\n",
        "        if existing:\n",
        "            return self.show_current_zones(), f\"⚠️ Mapping {from_zone_id} → {to_zone_id} already exists.\"\n",
        "\n",
        "        # Create mapping with user-specified turn type\n",
        "        new_mapping = {\n",
        "            'from_zone': from_zone_id,\n",
        "            'to_zone': to_zone_id,\n",
        "            'turn_type': turn_type\n",
        "        }\n",
        "\n",
        "        self.turn_mappings.append(new_mapping)\n",
        "\n",
        "        result_image = self.create_zone_visualization()\n",
        "\n",
        "        icons = {\"left\": \"⬅️\", \"right\": \"➡️\", \"straight\": \"⬆️\", \"u-turn\": \"🔄\"}\n",
        "        icon = icons.get(turn_type, \"📍\")\n",
        "\n",
        "        return result_image, f\"✅ Added mapping: {from_zone_id} → {to_zone_id} ({turn_type} {icon}). Total mappings: {len(self.turn_mappings)}\"\n",
        "\n",
        "    def clear_last_zone(self):\n",
        "        \"\"\"Remove the most recently drawn zone\"\"\"\n",
        "        if self.zones:\n",
        "            removed_zone = self.zones.pop()\n",
        "            # Remove any mappings involving this zone\n",
        "            self.turn_mappings = [m for m in self.turn_mappings\n",
        "                                if m['from_zone'] != removed_zone['id'] and m['to_zone'] != removed_zone['id']]\n",
        "            result_image = self.create_zone_visualization()\n",
        "            return result_image, f\"🗑️ Removed {removed_zone['id']} and related mappings. Remaining: {len(self.zones)} zones\"\n",
        "        else:\n",
        "            result_image = self.show_current_zones()\n",
        "            return result_image, f\"⚠️ No zones to remove.\"\n",
        "\n",
        "    def clear_all_zones(self):\n",
        "        \"\"\"Clear all zones and mappings\"\"\"\n",
        "        total_zones = len(self.zones)\n",
        "        total_mappings = len(self.turn_mappings)\n",
        "        self.zones = []\n",
        "        self.turn_mappings = []\n",
        "        self.zone_counter = 1\n",
        "        result_image = self.show_current_zones()\n",
        "        return result_image, f\"🔄 Cleared {total_zones} zones and {total_mappings} mappings.\"\n",
        "\n",
        "    def clear_last_mapping(self):\n",
        "        \"\"\"Remove the most recently created mapping\"\"\"\n",
        "        if self.turn_mappings:\n",
        "            removed_mapping = self.turn_mappings.pop()\n",
        "            result_image = self.create_zone_visualization()\n",
        "            return result_image, f\"🗑️ Removed mapping: {removed_mapping['from_zone']} → {removed_mapping['to_zone']}. Remaining: {len(self.turn_mappings)} mappings\"\n",
        "        else:\n",
        "            result_image = self.show_current_zones()\n",
        "            return result_image, f\"⚠️ No mappings to remove.\"\n",
        "\n",
        "    def get_zone_choices(self):\n",
        "        \"\"\"Get list of zone IDs for dropdowns\"\"\"\n",
        "        return [zone['id'] for zone in self.zones]\n",
        "\n",
        "    def get_in_zone_choices(self):\n",
        "        \"\"\"Get list of IN zone IDs for FROM dropdown\"\"\"\n",
        "        return [zone['id'] for zone in self.zones if zone['direction'] == 'in']\n",
        "\n",
        "    def get_out_zone_choices(self):\n",
        "        \"\"\"Get list of OUT zone IDs for TO dropdown\"\"\"\n",
        "        return [zone['id'] for zone in self.zones if zone['direction'] == 'out']\n",
        "\n",
        "    def get_zones_as_named_dict(self):\n",
        "        entry = [z for z in self.zones if z[\"direction\"] == \"in\"]\n",
        "        exit = [z for z in self.zones if z[\"direction\"] == \"out\"]\n",
        "        return {\"entry\": entry, \"exit\": exit}\n",
        "\n",
        "    def get_turn_mappings(self):\n",
        "        return self.turn_mappings\n",
        "\n",
        "    def get_zone_info_without_mappings(self):\n",
        "        return self.get_zone_info(show_mappings=False)\n",
        "\n",
        "    def get_zone_info_with_mappings(self):\n",
        "        return self.get_zone_info(show_mappings=True)\n",
        "\n",
        "    def get_zone_info(self,show_mappings=False):\n",
        "        \"\"\"Get current zone and mapping information\"\"\"\n",
        "        if not self.zones:\n",
        "            return \"Upload a video and draw some zones to see information here.\"\n",
        "\n",
        "        # Count by direction\n",
        "        in_count = len([z for z in self.zones if z['direction'] == 'in'])\n",
        "        out_count = len([z for z in self.zones if z['direction'] == 'out'])\n",
        "\n",
        "        # Create summary\n",
        "        info = f\"📊 **Zone Summary:**\\n\\n\"\n",
        "        info += f\"🎯 **Total Zones:** {len(self.zones)}\\n\"\n",
        "        info += f\"🟢 **IN Zones:** {in_count}\\n\"\n",
        "        info += f\"🔴 **OUT Zones:** {out_count}\\n\\n\"\n",
        "\n",
        "        info += f\"📋 **Zone Details:**\\n\"\n",
        "        for zone in self.zones:\n",
        "            dir_color = \"🟢\" if zone['direction'] == 'in' else \"🔴\"\n",
        "            info += f\"{dir_color} **{zone['id']}** - {zone['direction'].upper()}\\n\"\n",
        "\n",
        "        if show_mappings:\n",
        "            info += f\"\\n🔗 **Turn Mappings ({len(self.turn_mappings)}):**\\n\"\n",
        "            if self.turn_mappings:\n",
        "                for mapping in self.turn_mappings:\n",
        "                    info += f\"➡️ **{mapping['from_zone']} → {mapping['to_zone']}** ({mapping['turn_type']})\\n\"\n",
        "            else:\n",
        "                info += \"No mappings created yet. Go to Step 2 to create turn mappings.\\n\"\n",
        "\n",
        "        if show_mappings:\n",
        "            ready = len(self.zones) > 0 and len(self.turn_mappings) > 0\n",
        "            info += f\"\\n🎯 **Ready for Analysis:** {'✅ Yes' if ready else '❌ Need zones and mappings'}\"\n",
        "\n",
        "        return info\n",
        "\n",
        "\n",
        "    def get_zones_for_pipeline(self):\n",
        "        \"\"\"Get zones and mappings for enhanced pipeline analysis\"\"\"\n",
        "        return {\n",
        "            'zones': self.zones,\n",
        "            'mappings': self.turn_mappings,\n",
        "            'legacy_zones': self._convert_to_legacy_format()\n",
        "        }\n",
        "\n",
        "    def _convert_to_legacy_format(self):\n",
        "        \"\"\"Convert new format to legacy format for backward compatibility\"\"\"\n",
        "        legacy_zones = {'entry': [], 'exit': []}\n",
        "\n",
        "        for zone in self.zones:\n",
        "            if zone['direction'] == 'in':\n",
        "                legacy_zones['entry'].append(zone['points'])\n",
        "            else:\n",
        "                legacy_zones['exit'].append(zone['points'])\n",
        "\n",
        "        return legacy_zones\n",
        "\n",
        "# Initialize the enhanced zone drawer\n",
        "zone_drawer = ZoneDrawer()\n",
        "\n",
        "def analyze_video_with_zones(video_file_path):\n",
        "    \"\"\"Analyze video using enhanced zones and mappings\"\"\"\n",
        "    global global_pipeline, global_turn_json\n",
        "\n",
        "    if not video_file_path:\n",
        "        return None, \"Please upload a video file.\"\n",
        "\n",
        "    # Check if zones and mappings are created\n",
        "    enhanced_data = zone_drawer.get_zones_for_pipeline()\n",
        "\n",
        "    if not enhanced_data['zones']:\n",
        "        return None, \"❌ Please draw some zones before analyzing.\"\n",
        "\n",
        "    if not enhanced_data['mappings']:\n",
        "        return None, \"❌ Please create turn mappings before analyzing.\"\n",
        "\n",
        "    try:\n",
        "        # Create temporary file\n",
        "        with open(video_file_path, \"rb\") as source_file:\n",
        "            with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp4\") as tmp_file:\n",
        "                tmp_file.write(source_file.read())\n",
        "                tmp_video_path = tmp_file.name\n",
        "\n",
        "        raw_output_path = \"raw_output.mp4\"\n",
        "        browser_safe_path = \"final_output_with_summary.mp4\"\n",
        "\n",
        "        # Save enhanced zone data\n",
        "        zones_file = \"zones.json\"\n",
        "        with open(zones_file, 'w') as f:\n",
        "            json.dump(enhanced_data, f, indent=2)\n",
        "\n",
        "        zones_dict = zone_drawer.get_zones_as_named_dict()\n",
        "        turns = zone_drawer.get_turn_mappings()\n",
        "        # Run enhanced pipeline (you would need to modify your existing pipeline)\n",
        "        global_turn_json = run_full_vehicle_turn_pipeline(\n",
        "            source_video_path=tmp_video_path,\n",
        "            final_output_path=raw_output_path,\n",
        "            zones=zones_dict,\n",
        "            turn_mappings=turns\n",
        "        )\n",
        "\n",
        "        # Re-encode video\n",
        "        encode_to_browser_safe_mp4(raw_output_path, browser_safe_path)\n",
        "\n",
        "        # Create enhanced document store\n",
        "        text_data = convert_turn_stats_to_text(global_turn_json, enhanced_data)\n",
        "        global_pipeline = create_pipeline(text_data)\n",
        "\n",
        "        # Clean up\n",
        "        if os.path.exists(zones_file):\n",
        "            os.remove(zones_file)\n",
        "        if os.path.exists(tmp_video_path):\n",
        "            os.remove(tmp_video_path)\n",
        "\n",
        "        # Create summary\n",
        "        zone_count = len(enhanced_data['zones'])\n",
        "        mapping_count = len(enhanced_data['mappings'])\n",
        "\n",
        "        return browser_safe_path, f\"✅ Video analyzed with {zone_count} zones and {mapping_count} turn mappings! Enhanced analysis ready.\", \"/content/turn_analysis.png\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return None, f\"❌ Error during analysis: {str(e)}\", None\n",
        "\n",
        "def answer_question(user_question):\n",
        "    \"\"\"Answer questions about the analyzed video\"\"\"\n",
        "    if not global_pipeline or not global_turn_json:\n",
        "        return \"Please analyze a video first.\"\n",
        "    return global_pipeline(user_question)\n",
        "\n",
        "def encode_to_browser_safe_mp4(input_path: str, output_path: str):\n",
        "    \"\"\"Convert video to browser-safe format\"\"\"\n",
        "    cmd = [\n",
        "        \"ffmpeg\", \"-y\", \"-i\", input_path,\n",
        "        \"-vcodec\", \"libx264\", \"-preset\", \"ultrafast\",\n",
        "        \"-acodec\", \"aac\", \"-movflags\", \"+faststart\",\n",
        "        output_path\n",
        "    ]\n",
        "    try:\n",
        "        subprocess.run(cmd, check=True)\n",
        "    except subprocess.CalledProcessError:\n",
        "        print(\"Error: ffmpeg failed to convert video to browser-safe format.\")\n",
        "\n",
        "\n",
        "def update_zone_dropdowns():\n",
        "    \"\"\"Update dropdown choices when zones change\"\"\"\n",
        "    in_choices = zone_drawer.get_in_zone_choices()\n",
        "    out_choices = zone_drawer.get_out_zone_choices()\n",
        "    return gr.Dropdown(choices=in_choices), gr.Dropdown(choices=out_choices)\n",
        "\n",
        "# Create Enhanced Gradio interface\n",
        "def create_interface():\n",
        "    with gr.Blocks(title=\"🚗 Vehicle Turn Detection with Zone Mapping\", theme=gr.themes.Soft()) as interface:\n",
        "        gr.HTML(\"\"\"\n",
        "        <h1 style=\"text-align: center;\">🚗 Vehicle Turn Detection with Zone Mapping</h1>\n",
        "        <p style=\"text-align: center;\">Step 1: Draw IN/OUT zones → Step 2: Create turn mappings → Step 3: Analyze flows → Step 4: Ask questions</p>\n",
        "        \"\"\")\n",
        "\n",
        "        with gr.Tab(\"🎨 Step 1: Draw IN/OUT Zones\"):\n",
        "            with gr.Row():\n",
        "                with gr.Column(scale=2):\n",
        "                    # Video upload\n",
        "                    video_input = gr.File(\n",
        "                        label=\"📹 Upload Video\",\n",
        "                        file_types=[\".mp4\", \".avi\", \".mov\"],\n",
        "                        type=\"filepath\"\n",
        "                    )\n",
        "\n",
        "                    # Frame display and drawing area\n",
        "                    frame_display = gr.ImageEditor(\n",
        "                        label=\"🎨 Draw Zones (Click and drag to draw polygons)\",\n",
        "                        type=\"pil\",\n",
        "                        brush=gr.Brush(default_size=12),\n",
        "                        height=600\n",
        "                    )\n",
        "\n",
        "                    # Simplified control panel - only direction\n",
        "                    with gr.Row():\n",
        "                        zone_direction = gr.Radio(\n",
        "                            choices=[\"in\", \"out\"],\n",
        "                            value=\"in\",\n",
        "                            label=\"🎯 Zone Direction\",\n",
        "                            info=\"IN (Green) for vehicle entry, OUT (Red) for vehicle exit\"\n",
        "                        )\n",
        "\n",
        "                        direction_status = gr.Textbox(\n",
        "                            label=\"📍 Current Mode\",\n",
        "                            value=\"Drawing mode: IN zones (🟢 GREEN)\",\n",
        "                            interactive=False\n",
        "                        )\n",
        "\n",
        "                    # Zone control buttons\n",
        "                    with gr.Row():\n",
        "                        save_zone_btn = gr.Button(\"✅ Save Zone\", variant=\"primary\", size=\"lg\")\n",
        "                        clear_last_btn = gr.Button(\"🗑️ Remove Last Zone\")\n",
        "                        clear_all_btn = gr.Button(\"🔄 Reset All\")\n",
        "\n",
        "                    # Zone status\n",
        "                    zone_status = gr.Textbox(\n",
        "                        label=\"📢 Zone Status\",\n",
        "                        interactive=False,\n",
        "                        max_lines=2\n",
        "                    )\n",
        "\n",
        "                with gr.Column(scale=1):\n",
        "                    # Zone information\n",
        "                    zone_info = gr.Markdown(\n",
        "                        value=\"Upload a video to start drawing zones.\",\n",
        "                        label=\"📊 Zone Information\"\n",
        "                    )\n",
        "\n",
        "                    # Instructions\n",
        "                    gr.Markdown(\"\"\"\n",
        "                    ### 📖 Step 1 Instructions:\n",
        "\n",
        "                    1. **Upload** a video file\n",
        "                    2. **Select** zone direction (IN/OUT only)\n",
        "                    3. **Draw** polygons on the frame\n",
        "                    4. **Save** each zone after drawing\n",
        "                    5. Go to **Step 2** to define turn mappings\n",
        "\n",
        "                    ### 🎨 Simple Zone System:\n",
        "                    - **IN Zones** 🟢: Where vehicles enter the intersection\n",
        "                    - **OUT Zones** 🔴: Where vehicles exit the intersection\n",
        "                    - Each zone gets an ID (Z1, Z2, Z3...)\n",
        "                    - Turn types will be defined in Step 2\n",
        "\n",
        "                    ### 🔄 **Recommended Layout:**\n",
        "\n",
        "                    Draw zones at key entry and exit points:\n",
        "                    - **IN zones**: At each road entrance to intersection\n",
        "                    - **OUT zones**: At each road exit from intersection\n",
        "                    \"\"\")\n",
        "\n",
        "        with gr.Tab(\"🔗 Step 2: Create Turn Mappings\"):\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    gr.Markdown(\"### Define Traffic Flow Patterns\")\n",
        "                    gr.Markdown(\"Connect IN zones to OUT zones and specify the turn type:\")\n",
        "\n",
        "                    with gr.Row():\n",
        "                        from_zone = gr.Dropdown(\n",
        "                            label=\"🟢 FROM Zone (IN)\",\n",
        "                            info=\"Select source IN zone\",\n",
        "                            interactive=True\n",
        "                        )\n",
        "                        to_zone = gr.Dropdown(\n",
        "                            label=\"🔴 TO Zone (OUT)\",\n",
        "                            info=\"Select destination OUT zone\",\n",
        "                            interactive=True\n",
        "                        )\n",
        "\n",
        "                    # Turn type selector - NOW IN STEP 2\n",
        "                    turn_type_mapping = gr.Radio(\n",
        "                        choices=[\"left\", \"right\", \"straight\", \"u-turn\"],\n",
        "                        label=\"🚗 Turn Type\",\n",
        "                        info=\"What type of turn is this mapping?\",\n",
        "                        interactive=True\n",
        "                    )\n",
        "\n",
        "                    with gr.Row():\n",
        "                        create_mapping_btn = gr.Button(\"🔗 Create Mapping\", variant=\"primary\")\n",
        "                        clear_last_mapping_btn = gr.Button(\"🗑️ Remove Last Mapping\")\n",
        "\n",
        "                    mapping_status = gr.Textbox(\n",
        "                        label=\"🔗 Mapping Status\",\n",
        "                        interactive=False\n",
        "                    )\n",
        "\n",
        "                    zone_info_step2 = gr.Markdown(\n",
        "                        value=\"Draw zones and create mappings to see summary here.\",\n",
        "                        label=\"📊 Zone + Mapping Info\"\n",
        "                    )\n",
        "\n",
        "                with gr.Column():\n",
        "                    # Updated frame display with mappings\n",
        "                    mapping_display = gr.Image(\n",
        "                        label=\"🗺️ Zone Layout with Turn Mappings\",\n",
        "                        height=500\n",
        "                    )\n",
        "\n",
        "                    gr.Markdown(\"\"\"\n",
        "                    ### 🔗 **Step 2: Define Turn Types**\n",
        "\n",
        "                    Now you can specify exactly what type of turn each flow represents:\n",
        "\n",
        "                    **Turn Type Options:**\n",
        "                    - ⬅️ **Left Turn**: Vehicle turns left\n",
        "                    - ➡️ **Right Turn**: Vehicle turns right\n",
        "                    - ⬆️ **Straight**: Vehicle goes straight through\n",
        "                    - 🔄 **U-Turn**: Vehicle makes U-turn\n",
        "\n",
        "                    **Example Mappings:**\n",
        "                    - Z1 → Z4 (Straight)\n",
        "                    - Z1 → Z5 (Left)\n",
        "                    - Z2 → Z6 (Right)\n",
        "                    - Z3 → Z4 (U-Turn)\n",
        "\n",
        "                    **Yellow arrows** with turn type show your mappings.\n",
        "                    \"\"\")\n",
        "\n",
        "        with gr.Tab(\"🔍 Step 3: Analyze Video\"):\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    analyze_btn = gr.Button(\"🚀 Analyze Video with Turn Mappings\", variant=\"primary\", size=\"lg\")\n",
        "                    analysis_status = gr.Textbox(label=\"📊 Analysis Status\", interactive=False)\n",
        "                    turn_analysis_image = gr.Image(label=\"🖼️ Turn Analysis Results\")\n",
        "\n",
        "                with gr.Column():\n",
        "                    video_output = gr.Video(label=\"📹 Processed Video with Flow Analysis\")\n",
        "\n",
        "        with gr.Tab(\"❓ Step 4: Ask Questions\"):\n",
        "            gr.Markdown(\"### Ask detailed questions about traffic flows:\")\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    question_input = gr.Textbox(\n",
        "                        label=\"💬 Your Question\",\n",
        "                        placeholder=\"e.g., How many vehicles turned left from Z1 to Z5? Which turn type had the most traffic?\",\n",
        "                        lines=3\n",
        "                    )\n",
        "                with gr.Column():\n",
        "                    answer_output = gr.Textbox(\n",
        "                        label=\"🤖 Analysis Answer\",\n",
        "                        lines=6,\n",
        "                        interactive=False\n",
        "                    )\n",
        "\n",
        "            gr.Markdown(\"\"\"\n",
        "            ### 💡 **Example Questions:**\n",
        "            - \"How many left turns were made from Z1 to Z5?\"\n",
        "            - \"Which turn mapping had the highest traffic volume?\"\n",
        "            - \"Compare straight-through vs turning traffic\"\n",
        "            - \"What percentage of vehicles from Z1 went straight vs turned?\"\n",
        "            - \"Show me all U-turn statistics\"\n",
        "            \"\"\")\n",
        "\n",
        "        # Event handlers for Step 1 - zone drawing only\n",
        "        video_input.change(\n",
        "            fn=zone_drawer.process_video,\n",
        "            inputs=[video_input],\n",
        "            outputs=[frame_display, zone_status]\n",
        "        ).then(\n",
        "            fn=update_zone_dropdowns,\n",
        "            outputs=[from_zone, to_zone]\n",
        "        )\n",
        "\n",
        "        zone_direction.change(\n",
        "            fn=zone_drawer.set_zone_direction,\n",
        "            inputs=[zone_direction],\n",
        "            outputs=[direction_status]\n",
        "        )\n",
        "\n",
        "        # Event handlers for zone drawing\n",
        "        save_zone_btn.click(\n",
        "            fn=zone_drawer.process_drawing,\n",
        "            inputs=[frame_display],\n",
        "            outputs=[frame_display, zone_status]\n",
        "        ).then(\n",
        "            fn=zone_drawer.get_zone_info_without_mappings,\n",
        "            outputs=[zone_info]\n",
        "        ).then(\n",
        "            fn=update_zone_dropdowns,\n",
        "            outputs=[from_zone, to_zone]\n",
        "        ).then(\n",
        "            fn=zone_drawer.show_current_zones,\n",
        "            outputs=[mapping_display]\n",
        "        )\n",
        "\n",
        "        clear_last_btn.click(\n",
        "            fn=zone_drawer.clear_last_zone,\n",
        "            outputs=[frame_display, zone_status]\n",
        "        ).then(\n",
        "            fn=zone_drawer.get_zone_info_without_mappings,\n",
        "            outputs=[zone_info]\n",
        "        ).then(\n",
        "            fn=update_zone_dropdowns,\n",
        "            outputs=[from_zone, to_zone]\n",
        "        ).then(\n",
        "            fn=zone_drawer.show_current_zones,\n",
        "            outputs=[mapping_display]\n",
        "        )\n",
        "\n",
        "        clear_all_btn.click(\n",
        "            fn=zone_drawer.clear_all_zones,\n",
        "            outputs=[frame_display, zone_status]\n",
        "        ).then(\n",
        "            fn=zone_drawer.get_zone_info_without_mappings,\n",
        "            outputs=[zone_info]\n",
        "        ).then(\n",
        "            fn=update_zone_dropdowns,\n",
        "            outputs=[from_zone, to_zone]\n",
        "        ).then(\n",
        "            fn=zone_drawer.show_current_zones,\n",
        "            outputs=[mapping_display]\n",
        "        )\n",
        "\n",
        "        # Event handlers for turn mappings\n",
        "        create_mapping_btn.click(\n",
        "            fn=zone_drawer.create_turn_mapping,\n",
        "            inputs=[from_zone, to_zone, turn_type_mapping],\n",
        "            outputs=[mapping_display, mapping_status]\n",
        "        ).then(\n",
        "            fn=zone_drawer.get_zone_info_with_mappings,\n",
        "            outputs=[zone_info_step2]\n",
        "        )\n",
        "\n",
        "        clear_last_mapping_btn.click(\n",
        "            fn=zone_drawer.clear_last_mapping,\n",
        "            outputs=[mapping_display, mapping_status]\n",
        "        ).then(\n",
        "            fn=zone_drawer.get_zone_info_with_mappings,\n",
        "            outputs=[zone_info_step2]\n",
        "        )\n",
        "\n",
        "        # Update mapping display when zones change\n",
        "        from_zone.change(\n",
        "            fn=zone_drawer.show_current_zones,\n",
        "            outputs=[mapping_display]\n",
        "        )\n",
        "\n",
        "        to_zone.change(\n",
        "            fn=zone_drawer.show_current_zones,\n",
        "            outputs=[mapping_display]\n",
        "        )\n",
        "\n",
        "        # Event handler for enhanced video analysis\n",
        "        analyze_btn.click(\n",
        "            fn=lambda: analyze_video_with_zones(zone_drawer.video_path),\n",
        "            outputs=[video_output, analysis_status, turn_analysis_image]\n",
        "        )\n",
        "\n",
        "        # Event handler for Q&A\n",
        "        question_input.submit(\n",
        "            fn=answer_question,\n",
        "            inputs=[question_input],\n",
        "            outputs=[answer_output]\n",
        "        )\n",
        "\n",
        "        question_input.change(\n",
        "            fn=answer_question,\n",
        "            inputs=[question_input],\n",
        "            outputs=[answer_output]\n",
        "        )\n",
        "\n",
        "    return interface\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    interface = create_interface()\n",
        "    interface.launch(\n",
        "        share=True,\n",
        "        debug=True,\n",
        "        show_error=True\n",
        "    )"
      ],
      "metadata": {
        "id": "poZkRxgV_DJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# zones = [\n",
        "#     {\n",
        "#       \"id\": \"Z1\",\n",
        "#       \"direction\": \"in\",\n",
        "#       \"points\": [\n",
        "#         [\n",
        "#           1167,\n",
        "#           379\n",
        "#         ],\n",
        "#         [\n",
        "#           1496,\n",
        "#           585\n",
        "#         ],\n",
        "#         [\n",
        "#           1598,\n",
        "#           418\n",
        "#         ],\n",
        "#         [\n",
        "#           1337,\n",
        "#           232\n",
        "#         ]\n",
        "#       ]\n",
        "#     },\n",
        "#     {\n",
        "#       \"id\": \"Z2\",\n",
        "#       \"direction\": \"in\",\n",
        "#       \"points\": [\n",
        "#         [\n",
        "#           1330,\n",
        "#           822\n",
        "#         ],\n",
        "#         [\n",
        "#           1231,\n",
        "#           749\n",
        "#         ],\n",
        "#         [\n",
        "#           1035,\n",
        "#           968\n",
        "#         ],\n",
        "#         [\n",
        "#           1017,\n",
        "#           1031\n",
        "#         ],\n",
        "#         [\n",
        "#           1107,\n",
        "#           1045\n",
        "#         ]\n",
        "#       ]\n",
        "#     },\n",
        "#     {\n",
        "#       \"id\": \"Z3\",\n",
        "#       \"direction\": \"in\",\n",
        "#       \"points\": [\n",
        "#         [\n",
        "#           1064,\n",
        "#           118\n",
        "#         ],\n",
        "#         [\n",
        "#           921,\n",
        "#           54\n",
        "#         ],\n",
        "#         [\n",
        "#           667,\n",
        "#           265\n",
        "#         ],\n",
        "#         [\n",
        "#           790,\n",
        "#           389\n",
        "#         ]\n",
        "#       ]\n",
        "#     },\n",
        "#     {\n",
        "#       \"id\": \"Z4\",\n",
        "#       \"direction\": \"in\",\n",
        "#       \"points\": [\n",
        "#         [\n",
        "#           548,\n",
        "#           586\n",
        "#         ],\n",
        "#         [\n",
        "#           504,\n",
        "#           689\n",
        "#         ],\n",
        "#         [\n",
        "#           715,\n",
        "#           882\n",
        "#         ],\n",
        "#         [\n",
        "#           837,\n",
        "#           791\n",
        "#         ],\n",
        "#         [\n",
        "#           788,\n",
        "#           732\n",
        "#         ]\n",
        "#       ]\n",
        "#     },\n",
        "#     {\n",
        "#       \"id\": \"Z5\",\n",
        "#       \"direction\": \"out\",\n",
        "#       \"points\": [\n",
        "#         [\n",
        "#           668,\n",
        "#           266\n",
        "#         ],\n",
        "#         [\n",
        "#           450,\n",
        "#           414\n",
        "#         ],\n",
        "#         [\n",
        "#           528,\n",
        "#           569\n",
        "#         ],\n",
        "#         [\n",
        "#           779,\n",
        "#           393\n",
        "#         ]\n",
        "#       ]\n",
        "#     },\n",
        "#     {\n",
        "#       \"id\": \"Z6\",\n",
        "#       \"direction\": \"out\",\n",
        "#       \"points\": [\n",
        "#         [\n",
        "#           1157,\n",
        "#           28\n",
        "#         ],\n",
        "#         [\n",
        "#           1089,\n",
        "#           83\n",
        "#         ],\n",
        "#         [\n",
        "#           1087,\n",
        "#           131\n",
        "#         ],\n",
        "#         [\n",
        "#           1174,\n",
        "#           362\n",
        "#         ],\n",
        "#         [\n",
        "#           1331,\n",
        "#           209\n",
        "#         ]\n",
        "#       ]\n",
        "#     },\n",
        "#     {\n",
        "#       \"id\": \"Z7\",\n",
        "#       \"direction\": \"out\",\n",
        "#       \"points\": [\n",
        "#         [\n",
        "#           1597,\n",
        "#           724\n",
        "#         ],\n",
        "#         [\n",
        "#           1522,\n",
        "#           626\n",
        "#         ],\n",
        "#         [\n",
        "#           1285,\n",
        "#           774\n",
        "#         ],\n",
        "#         [\n",
        "#           1402,\n",
        "#           870\n",
        "#         ]\n",
        "#       ]\n",
        "#     },\n",
        "#     {\n",
        "#       \"id\": \"Z8\",\n",
        "#       \"direction\": \"out\",\n",
        "#       \"points\": [\n",
        "#         [\n",
        "#           700,\n",
        "#           880\n",
        "#         ],\n",
        "#         [\n",
        "#           838,\n",
        "#           1046\n",
        "#         ],\n",
        "#         [\n",
        "#           993,\n",
        "#           1013\n",
        "#         ],\n",
        "#         [\n",
        "#           808,\n",
        "#           800\n",
        "#         ]\n",
        "#       ]\n",
        "#     }\n",
        "#   ]\n",
        "\n",
        "# mappings = [\n",
        "#     {\n",
        "#       \"from_zone\": \"Z1\",\n",
        "#       \"to_zone\": \"Z8\",\n",
        "#       \"turn_type\": \"straight\"\n",
        "#     },\n",
        "#     {\n",
        "#       \"from_zone\": \"Z1\",\n",
        "#       \"to_zone\": \"Z5\",\n",
        "#       \"turn_type\": \"right\"\n",
        "#     },\n",
        "#     {\n",
        "#       \"from_zone\": \"Z1\",\n",
        "#       \"to_zone\": \"Z7\",\n",
        "#       \"turn_type\": \"left\"\n",
        "#     },\n",
        "#     {\n",
        "#       \"from_zone\": \"Z1\",\n",
        "#       \"to_zone\": \"Z6\",\n",
        "#       \"turn_type\": \"u-turn\"\n",
        "#     },\n",
        "#     {\n",
        "#       \"from_zone\": \"Z2\",\n",
        "#       \"to_zone\": \"Z6\",\n",
        "#       \"turn_type\": \"right\"\n",
        "#     },\n",
        "#     {\n",
        "#       \"from_zone\": \"Z2\",\n",
        "#       \"to_zone\": \"Z5\",\n",
        "#       \"turn_type\": \"straight\"\n",
        "#     },\n",
        "#     {\n",
        "#       \"from_zone\": \"Z2\",\n",
        "#       \"to_zone\": \"Z8\",\n",
        "#       \"turn_type\": \"left\"\n",
        "#     },\n",
        "#     {\n",
        "#       \"from_zone\": \"Z2\",\n",
        "#       \"to_zone\": \"Z7\",\n",
        "#       \"turn_type\": \"u-turn\"\n",
        "#     },\n",
        "#     {\n",
        "#       \"from_zone\": \"Z3\",\n",
        "#       \"to_zone\": \"Z7\",\n",
        "#       \"turn_type\": \"straight\"\n",
        "#     },\n",
        "#     {\n",
        "#       \"from_zone\": \"Z3\",\n",
        "#       \"to_zone\": \"Z8\",\n",
        "#       \"turn_type\": \"right\"\n",
        "#     },\n",
        "#     {\n",
        "#       \"from_zone\": \"Z3\",\n",
        "#       \"to_zone\": \"Z6\",\n",
        "#       \"turn_type\": \"left\"\n",
        "#     },\n",
        "#     {\n",
        "#       \"from_zone\": \"Z3\",\n",
        "#       \"to_zone\": \"Z5\",\n",
        "#       \"turn_type\": \"u-turn\"\n",
        "#     },\n",
        "#     {\n",
        "#       \"from_zone\": \"Z4\",\n",
        "#       \"to_zone\": \"Z5\",\n",
        "#       \"turn_type\": \"left\"\n",
        "#     },\n",
        "#     {\n",
        "#       \"from_zone\": \"Z4\",\n",
        "#       \"to_zone\": \"Z6\",\n",
        "#       \"turn_type\": \"straight\"\n",
        "#     },\n",
        "#     {\n",
        "#       \"from_zone\": \"Z4\",\n",
        "#       \"to_zone\": \"Z8\",\n",
        "#       \"turn_type\": \"u-turn\"\n",
        "#     },\n",
        "#     {\n",
        "#       \"from_zone\": \"Z4\",\n",
        "#       \"to_zone\": \"Z7\",\n",
        "#       \"turn_type\": \"right\"\n",
        "#     }\n",
        "#   ]\n",
        "\n",
        "\n",
        "# def get_zones_as_named_dict(zones):\n",
        "#     entry = [z for z in zones if z[\"direction\"] == \"in\"]\n",
        "#     exit = [z for z in zones if z[\"direction\"] == \"out\"]\n",
        "#     return {\"entry\": entry, \"exit\": exit}"
      ],
      "metadata": {
        "id": "ktbnkeu0YifW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run_full_vehicle_turn_pipeline(\n",
        "#             source_video_path=\"/content/traffic_chaos.mp4\",\n",
        "#             final_output_path=\"outwithturns.mp4\",\n",
        "#             zones=get_zones_as_named_dict(zones),\n",
        "#             turn_mappings=mappings\n",
        "#         )"
      ],
      "metadata": {
        "id": "D9VvQudAYi5v"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}